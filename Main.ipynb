{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:\\BotGauge\\NewTask2\\.venv\\lib\\site-packages\\beir\\datasets\\data_loader.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "100%|██████████| 2681468/2681468 [00:12<00:00, 220585.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Questions Corpus: 2681468 Queries: 3452 Qrels: 3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5233329/5233329 [00:22<00:00, 232610.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotpotQA Corpus: 5233329 Queries: 7405 Qrels: 7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 204690.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiQA Corpus: 57638 Queries: 648 Qrels: 648\n",
      "\n",
      "Sample from Natural Questions Corpus:\n",
      "Doc ID: doc0, Content: In accounting, minority interest (or non-controlling interest) is the portion of a subsidiary corporation's stock that is not owned by the parent corporation. The magnitude of the minority interest in...\n",
      "Doc ID: doc1, Content: It is, however, possible (such as through special voting rights) for a controlling interest requiring consolidation to be achieved without exceeding 50% ownership, depending on the accounting standard...\n",
      "Doc ID: doc2, Content: The reporting of 'minority interest' is a consequence of the requirement by accounting standards to 'fully' consolidate partly owned subsidiaries. Full consolidation, as opposed to partial consolidati...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "# Define dataset paths\n",
    "base_path = r\"T:\\BotGauge\"\n",
    "nq_path = os.path.join(base_path, \"NaturalQuestions\")\n",
    "hotpotqa_path = os.path.join(base_path, \"HotpotQA\")\n",
    "fiqa_path = os.path.join(base_path, \"fiQA\")\n",
    "\n",
    "# Function to load and print dataset statistics\n",
    "def load_and_print_stats(dataset_name, dataset_path):\n",
    "    corpus, queries, qrels = GenericDataLoader(data_folder=dataset_path).load(split=\"test\")\n",
    "    print(f\"{dataset_name} Corpus: {len(corpus)} Queries: {len(queries)} Qrels: {len(qrels)}\")\n",
    "    return corpus, queries, qrels\n",
    "\n",
    "# Load and print statistics for each dataset\n",
    "nq_corpus, nq_queries, nq_qrels = load_and_print_stats(\"Natural Questions\", nq_path)\n",
    "hotpotqa_corpus, hotpotqa_queries, hotpotqa_qrels = load_and_print_stats(\"HotpotQA\", hotpotqa_path)\n",
    "fiqa_corpus, fiqa_queries, fiqa_qrels = load_and_print_stats(\"FiQA\", fiqa_path)\n",
    "\n",
    "# Example: Accessing first few entries from Natural Questions corpus\n",
    "print(\"\\nSample from Natural Questions Corpus:\")\n",
    "for doc_id, doc_info in list(nq_corpus.items())[:3]:\n",
    "    print(f\"Doc ID: {doc_id}, Content: {doc_info['text'][:200]}...\")  # Print first 200 chars of the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the NVIDIA embedding model\n",
    "small_model = SentenceTransformer('nvidia/NV-Embed-v2', trust_remote_code=True)\n",
    "\n",
    "# Define a sample query\n",
    "query = \"What is quantum computing?\"\n",
    "\n",
    "# Encode the query\n",
    "query_embedding = small_model.encode(query)\n",
    "\n",
    "# Encode all documents in the corpus (you can limit this to a smaller subset for testing)\n",
    "doc_embeddings = [small_model.encode(doc['text']) for doc_id, doc in nq_corpus.items()]\n",
    "\n",
    "# Compute cosine similarity between the query and documents\n",
    "similarities = cosine_similarity([query_embedding], doc_embeddings)\n",
    "\n",
    "# Get top-k most relevant documents\n",
    "top_k = 5\n",
    "top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]\n",
    "top_k_docs = [list(nq_corpus.items())[i] for i in top_k_indices]\n",
    "\n",
    "# Print the top-k document IDs and their similarity scores\n",
    "print(\"\\nTop-k Documents:\")\n",
    "for i, (doc_id, _) in enumerate(top_k_docs):\n",
    "    print(f\"Rank {i+1}: Document ID: {doc_id}, Similarity Score: {similarities[0][top_k_indices[i]]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the ranking model\n",
    "rank_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2' trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2' trust_remote_code=True)\n",
    "\n",
    "# Rerank the top-k documents\n",
    "reranked_docs = []\n",
    "for doc_id, doc in top_k_docs:\n",
    "    inputs = tokenizer(\"Query: \" + query, \"Passage: \" + doc['text'], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        score = rank_model(**inputs).logits.item()\n",
    "    reranked_docs.append((doc_id, score))\n",
    "\n",
    "# Sort by reranking scores\n",
    "reranked_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print reranked document IDs and their scores\n",
    "print(\"\\nReranked Documents:\")\n",
    "for i, (doc_id, score) in enumerate(reranked_docs):\n",
    "    print(f\"Rank {i+1}: Document ID: {doc_id}, Reranking Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the ranking model\n",
    "rank_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2' trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2' trust_remote_code=True)\n",
    "\n",
    "# Rerank the top-k documents\n",
    "reranked_docs = []\n",
    "for doc_id, doc in top_k_docs:\n",
    "    inputs = tokenizer(\"Query: \" + query, \"Passage: \" + doc['text'], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        score = rank_model(**inputs).logits.item()\n",
    "    reranked_docs.append((doc_id, score))\n",
    "\n",
    "# Sort by reranking scores\n",
    "reranked_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print reranked document IDs and their scores\n",
    "print(\"\\nReranked Documents:\")\n",
    "for i, (doc_id, score) in enumerate(reranked_docs):\n",
    "    print(f\"Rank {i+1}: Document ID: {doc_id}, Reranking Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Example true relevance scores and predicted relevance scores\n",
    "true_relevance = np.asarray([[1, 0, 1, 0, 0]])  # Replace with actual relevance for your documents\n",
    "predicted_scores = np.asarray([[score for _, score in reranked_docs]])  # Scores from reranked_docs\n",
    "\n",
    "# Calculate NDCG@10\n",
    "ndcg = ndcg_score(true_relevance, predicted_scores, k=10)\n",
    "print(f\"NDCG@10: {ndcg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
